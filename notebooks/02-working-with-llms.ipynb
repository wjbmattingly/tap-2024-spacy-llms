{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Firstname Lastname](https://) for the 2024 Text Analysis Pedagogy Institute, with support from [Constellate](https://constellate.org).\n",
    "\n",
    "For questions/comments/improvements, email author@email.address.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# `spaCy in the World of LLMs` `2`\n",
    "\n",
    "This is lesson `2` of 3 in the educational series on `spaCy and Large Language Models (LLMs)`. This notebook will introduce you to Large Language Models, the basic concepts behind theme, when to use them, and how to bring their outputs into a spaCy pipeline. \n",
    "\n",
    "**Skills:** \n",
    "* Python\n",
    "\n",
    "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** `Tutorial` / `Reference` / `Explanation` \n",
    "\n",
    "`Include the use case definition from [here](https://constellate.org/docs/documentation-categories)`\n",
    "\n",
    "**Difficulty:** `Beginner`\n",
    "\n",
    "`Beginner assumes users are relatively new to Python and Jupyter Notebooks. The user is helped step-by-step with lots of explanatory text.`\n",
    "`Intermediate assumes users are familiar with Python and have been programming for 6+ months. Code makes up a larger part of the notebook and basic concepts related to Python are not explained.`\n",
    "`Advanced assumes users are very familiar with Python and have been programming for years, but they may not be familiar with the process being explained.`\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "* A general understanding of natural language processing (NLP)\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Understand text processing pipelines\n",
    "2. Understand the basics of large language models (LLMs)\n",
    "3. Understand how to start using spacy-llm to bring LLM outputs into a spaCy pipeline\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c0555",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "`List out any libraries used and what they are used for`\n",
    "* [spaCy](https://spacy.io/) for performing [natural language processing](https://docs.constellate.org/key-terms/#nlp).\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a220f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Libraries ###\n",
    "\n",
    "# Using !pip installs\n",
    "!pip install spacy spacy-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a7884",
   "metadata": {},
   "source": [
    "Before starting this notebook, you **MUST** have an OpenAI API Key. To make one you can visit [OpenAI's website, make an account, and navigate to Platform](https://platform.openai.com/api-keys) and follow the directions seen in this gif.\n",
    "\n",
    "![openai api key](../images/openai-api-key.gif)\n",
    "\n",
    "The video covers these steps.\n",
    "\n",
    "1. Make an Account\n",
    "2. Visit the Dashboard\n",
    "3. Go to API Keys\n",
    "4. Create an API Key\n",
    "5. Paste it into this notebook in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "355a249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# uncomment this out if you are using a Mac. This is a bug and with spacy-llm and pytorch on a Mac and this resolves it for now.\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53edaa2",
   "metadata": {},
   "source": [
    "# Introduction to Large Language Models and spacy-llm\n",
    "\n",
    "Today, we will be looking at Large Language Models (LLMs) and `spacy-llm`. In this lesson, we will learn about the concepts behind LLMs, their strengths and weaknesses, and we will learn how they can be used for classification. We will learn about a few different methods of classification, from zero-shot to single and multi-shot classification. This background will allow us to then dive into NLP pipelines.\n",
    "\n",
    "After covering this introductory material, we can then learn about how LLMs can be easily introduced into a spaCy pipeline with `spacy-llm`. We will learn about APIs and how to properly setup an environment to work with API keys. While we will focus specifically on OpenAI, the methods introduced here will work for other LLM services as well as local models downloaded from HuggingFace.\n",
    "\n",
    "# What are Large Language Models?\n",
    "\n",
    "Large Language Models (LLMs) represent the cutting edge of natural language processing. These sophisticated AI systems are designed to comprehend, generate, and manipulate human language with proficiency. Built on deep learning architectures, typically employing transformer models, LLMs are trained on vast corpora of text data (trillions of tokens). This extensive training allows them to capture the subtle nuances of language, including complex grammatical structures, contextual meanings, and even rudimentary reasoning capabilities.\n",
    "\n",
    "LLMs are very versatile and can be used to solve (or partially solve) many NLP problems. From translation to summarization, from question-answering to creative writing, these models demonstrate a wide-ranging applicability across numerous language tasks. You might be familiar with some popular examples, such as the GPT (Generative Pre-trained Transformer) series, the basis for ChatGPT. These models have played a pivotal role in revolutionizing natural language processing, enabling more human-like text generation and understanding than ever before.\n",
    "\n",
    "# The strengths and weaknesses\n",
    "\n",
    "Like any technology, LLMs come with their own set of strengths and weaknesses. On the positive side, they have the ability to adapt to various language tasks without requiring task-specific training. This is very different from traditional task-specific machine learning models. Their contextual understanding allows them to grasp nuances in language that previous models struggled with. Moreover, their generation capabilities enable them to produce human-like text for diverse purposes. One of their most impressive features is few-shot learning – the ability to adapt to new tasks with minimal examples.\n",
    "\n",
    "Yet, it's crucial to be aware of their limitations. Despite their impressive abilities, LLMs lack true real-world knowledge and may generate plausible-sounding but factually incorrect information. This is known as a `hallucination` They can inadvertently perpetuate societal biases present in their training data. From a practical standpoint, they demand significant computational resources to train and run. It's also important to note that while they can mimic reasoning, they don't truly \"understand\" in a human sense, and they may struggle with consistency, potentially providing different answers to the same question asked in different ways.\n",
    "\n",
    "# Zero-Shot, Single-Shot, and Multi-Shot Classification\n",
    "\n",
    "As we dive deeper into working with LLMs, you'll encounter terms like Zero-Shot, Single-Shot, and Multi-Shot Classification. These refer to different approaches in using LLMs for classification tasks. \n",
    "\n",
    "Zero-Shot Classification is particularly intriguing – it involves the model classifying inputs into categories it hasn't been explicitly trained on, relying instead on its general language understanding to infer appropriate categories. Imagine classifying news articles into topics without providing any specific examples – that's Zero-Shot Classification in action.\n",
    "\n",
    "Single-Shot Classification takes this a step further by giving the model one example of each category before making classifications. This approach is invaluable when you have very limited labeled data available. For instance, you might provide one example each of a positive and negative review before conducting sentiment analysis.\n",
    "\n",
    "Multi-Shot Classification, as the name suggests, provides the model with multiple examples for each category. This method typically improves accuracy by giving the model more context about each category. Think of it as giving several examples of different animal species before asking the model to classify new animals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140d700",
   "metadata": {},
   "source": [
    "# What are Pipelines?\n",
    "\n",
    "Now, let's talk about pipelines, a crucial concept in NLP and specifically in spacy-llm. In essence, pipelines are sequences of data processing components that work together to analyze text. They're the backbone of efficient and modular text processing systems. In the context of spacy-llm, pipelines play a vital role in integrating Large Language Models into spaCy's ecosystem, allowing for a seamless combination of rule-based and statistical NLP with LLM capabilities.\n",
    "\n",
    "A typical NLP pipeline might include components like tokenization (breaking text into individual tokens), part-of-speech tagging (assigning grammatical categories to tokens), named entity recognition (identifying and categorizing named entities), and dependency parsing (analyzing the grammatical structure of sentences). With spacy-llm, we can now integrate LLM capabilities into these pipelines, using them for tasks like classification, generation, or analysis.\n",
    "\n",
    "The beauty of pipelines lies in their standardization, efficiency, and flexibility. They provide a consistent interface for various NLP tasks, are optimized for performance and easy to scale, and can be customized and extended based on specific needs. In the context of spacy-llm, this means you can seamlessly integrate LLM capabilities into existing spaCy workflows, enabling powerful hybrid approaches that combine traditional NLP techniques with the advanced capabilities of Large Language Models.\n",
    "\n",
    "As we progress through this lesson, you'll gain hands-on experience with these concepts, learning how to leverage the full potential of both spaCy and Large Language Models in your NLP projects. Whether you're looking to classify text, generate human-like responses, or perform complex language analysis, the combination of LLMs and spacy-llm provides a powerful toolkit for tackling a wide range of natural language processing challenges.\n",
    "\n",
    "So, let's roll up our sleeves and dive into the exciting world of Large Language Models and spacy-llm. By the end of this lesson, you'll have a solid foundation in these cutting-edge technologies and practical knowledge of how to apply them in real-world scenarios. Get ready to unlock new possibilities in your NLP journey!\n",
    "\n",
    "# spaCy Pipeline\n",
    "\n",
    "Let's take a look at a typical spaCy pipeline. To do that, we will load up the `en_core_web_sm` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446407d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32721e81",
   "metadata": {},
   "source": [
    "Now that we have it loaded into memory, let's go ahead and access the pipe names by using `.pipe_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cd7727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2dbeb",
   "metadata": {},
   "source": [
    "This shows us the sequence of the pipes.\n",
    "\n",
    "1. 'tok2vec': This is the first step in the pipeline. It stands for \"tokenization to vectors\". This component converts text into numerical vectors that represent the semantic meaning of each token. It's a crucial preprocessing step for many other components.\n",
    "2. 'tagger': This component performs part-of-speech (POS) tagging. It assigns grammatical categories (like noun, verb, adjective, etc.) to each token in the text.\n",
    "3. 'parser': The parser analyzes the grammatical structure of the sentence. It determines the relationships between words and creates a dependency parse tree.\n",
    "4. 'attribute_ruler': This component can be used to add, modify or remove token attributes based on token or span matches. It's often used for rule-based corrections or additions to the pipeline's output.\n",
    "5. 'lemmatizer': The lemmatizer reduces words to their base or dictionary form. For example, \"running\" would be lemmatized to \"run\".\n",
    "6. 'ner': This stands for Named Entity Recognition. It identifies and classifies named entities (like persons, organizations, locations, etc.) in the text.\n",
    "\n",
    "This sequence represents a common order of operations in NLP:\n",
    "\n",
    "First, the text is tokenized and converted to vectors. Then, grammatical information is added (tagging and parsing). Additional attributes might be adjusted. Words are reduced to their base forms. Finally, named entities are identified.\n",
    "\n",
    "Each step in this pipeline builds on the previous ones, creating a rich set of linguistic annotations for the input text. This particular pipeline is quite comprehensive and would be suitable for a wide range of NLP tasks.\n",
    "\n",
    "We can analyze this pipeline further with the `.analyze_pipes()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2091e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': []},\n",
       " 'attrs': {'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561daa2",
   "metadata": {},
   "source": [
    "# spaCy Config System\n",
    "\n",
    "As of spaCy version 3, a spaCy pipeline is based on a config system. This controls the pipeline, location of important assets, such as training data, defines pipes and points the pipeline to the correct machine learning models to use. If we want to examine the config file of a given spaCy pipeline, we can use `nlp.config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f79b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': {'train': None, 'dev': None, 'vectors': None, 'init_tok2vec': None},\n",
       " 'system': {'gpu_allocator': None, 'seed': 0},\n",
       " 'nlp': {'lang': 'en',\n",
       "  'pipeline': ['tok2vec',\n",
       "   'tagger',\n",
       "   'parser',\n",
       "   'senter',\n",
       "   'attribute_ruler',\n",
       "   'lemmatizer',\n",
       "   'ner'],\n",
       "  'disabled': ['senter'],\n",
       "  'before_creation': None,\n",
       "  'after_creation': None,\n",
       "  'after_pipeline_creation': None,\n",
       "  'batch_size': 256,\n",
       "  'tokenizer': {'@tokenizers': 'spacy.Tokenizer.v1'},\n",
       "  'vectors': {'@vectors': 'spacy.Vectors.v1'}},\n",
       " 'components': {'tok2vec': {'factory': 'tok2vec',\n",
       "   'model': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "    'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "     'width': '${components.tok2vec.model.encode:width}',\n",
       "     'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY', 'IS_SPACE'],\n",
       "     'rows': [5000, 1000, 2500, 2500, 50, 50],\n",
       "     'include_static_vectors': False},\n",
       "    'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "     'width': 96,\n",
       "     'depth': 4,\n",
       "     'window_size': 1,\n",
       "     'maxout_pieces': 3}}},\n",
       "  'tagger': {'factory': 'tagger',\n",
       "   'label_smoothing': 0.0,\n",
       "   'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "    'nO': None,\n",
       "    'normalize': False,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "     'width': '${components.tok2vec.model.encode:width}',\n",
       "     'upstream': 'tok2vec'}},\n",
       "   'neg_prefix': '!',\n",
       "   'overwrite': False,\n",
       "   'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}},\n",
       "  'parser': {'factory': 'parser',\n",
       "   'learn_tokens': False,\n",
       "   'min_action_freq': 30,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'parser',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 64,\n",
       "    'maxout_pieces': 2,\n",
       "    'use_upper': True,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2VecListener.v1',\n",
       "     'width': '${components.tok2vec.model.encode:width}',\n",
       "     'upstream': 'tok2vec'}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.parser_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100},\n",
       "  'senter': {'factory': 'senter',\n",
       "   'model': {'@architectures': 'spacy.Tagger.v2',\n",
       "    'nO': None,\n",
       "    'normalize': False,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "     'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "      'width': 16,\n",
       "      'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE', 'SPACY'],\n",
       "      'rows': [1000, 500, 500, 500, 50],\n",
       "      'include_static_vectors': False},\n",
       "     'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "      'width': 16,\n",
       "      'depth': 2,\n",
       "      'window_size': 1,\n",
       "      'maxout_pieces': 2}}},\n",
       "   'overwrite': False,\n",
       "   'scorer': {'@scorers': 'spacy.senter_scorer.v1'}},\n",
       "  'attribute_ruler': {'factory': 'attribute_ruler',\n",
       "   'scorer': {'@scorers': 'spacy.attribute_ruler_scorer.v1'},\n",
       "   'validate': False},\n",
       "  'lemmatizer': {'factory': 'lemmatizer',\n",
       "   'mode': 'rule',\n",
       "   'model': None,\n",
       "   'overwrite': False,\n",
       "   'scorer': {'@scorers': 'spacy.lemmatizer_scorer.v1'}},\n",
       "  'ner': {'factory': 'ner',\n",
       "   'incorrect_spans_key': None,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'ner',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 64,\n",
       "    'maxout_pieces': 2,\n",
       "    'use_upper': True,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "     'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "      'width': 96,\n",
       "      'attrs': ['NORM', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "      'rows': [5000, 1000, 2500, 2500],\n",
       "      'include_static_vectors': False},\n",
       "     'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "      'width': 96,\n",
       "      'depth': 4,\n",
       "      'window_size': 1,\n",
       "      'maxout_pieces': 3}}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100}},\n",
       " 'corpora': {'dev': {'@readers': 'spacy.Corpus.v1',\n",
       "   'path': '${paths.dev}',\n",
       "   'gold_preproc': False,\n",
       "   'max_length': 0,\n",
       "   'limit': 0,\n",
       "   'augmenter': None},\n",
       "  'train': {'@readers': 'spacy.Corpus.v1',\n",
       "   'path': '${paths.train}',\n",
       "   'gold_preproc': False,\n",
       "   'max_length': 0,\n",
       "   'limit': 0,\n",
       "   'augmenter': None}},\n",
       " 'training': {'train_corpus': 'corpora.train',\n",
       "  'dev_corpus': 'corpora.dev',\n",
       "  'seed': '${system:seed}',\n",
       "  'gpu_allocator': '${system:gpu_allocator}',\n",
       "  'dropout': 0.1,\n",
       "  'accumulate_gradient': 1,\n",
       "  'patience': 5000,\n",
       "  'max_epochs': 0,\n",
       "  'max_steps': 100000,\n",
       "  'eval_frequency': 1000,\n",
       "  'frozen_components': [],\n",
       "  'before_to_disk': None,\n",
       "  'annotating_components': [],\n",
       "  'before_update': None,\n",
       "  'batcher': {'@batchers': 'spacy.batch_by_words.v1',\n",
       "   'discard_oversize': False,\n",
       "   'tolerance': 0.2,\n",
       "   'get_length': None,\n",
       "   'size': {'@schedules': 'compounding.v1',\n",
       "    'start': 100,\n",
       "    'stop': 1000,\n",
       "    'compound': 1.001,\n",
       "    't': 0.0}},\n",
       "  'logger': {'@loggers': 'spacy.ConsoleLogger.v1', 'progress_bar': False},\n",
       "  'optimizer': {'@optimizers': 'Adam.v1',\n",
       "   'beta1': 0.9,\n",
       "   'beta2': 0.999,\n",
       "   'L2_is_weight_decay': True,\n",
       "   'L2': 0.01,\n",
       "   'grad_clip': 1.0,\n",
       "   'use_averages': True,\n",
       "   'eps': 1e-08,\n",
       "   'learn_rate': 0.001},\n",
       "  'score_weights': {'tag_acc': 0.16,\n",
       "   'dep_uas': 0.0,\n",
       "   'dep_las': 0.16,\n",
       "   'dep_las_per_type': None,\n",
       "   'sents_p': None,\n",
       "   'sents_r': None,\n",
       "   'sents_f': 0.02,\n",
       "   'lemma_acc': 0.5,\n",
       "   'ents_f': 0.16,\n",
       "   'ents_p': 0.0,\n",
       "   'ents_r': 0.0,\n",
       "   'ents_per_type': None,\n",
       "   'speed': 0.0}},\n",
       " 'pretraining': {},\n",
       " 'initialize': {'vocab_data': None,\n",
       "  'vectors': '${paths.vectors}',\n",
       "  'init_tok2vec': '${paths.init_tok2vec}',\n",
       "  'before_init': None,\n",
       "  'after_init': None,\n",
       "  'components': {'ner': {'labels': {'@readers': 'spacy.read_labels.v1',\n",
       "     'path': 'corpus/labels/ner.json',\n",
       "     'require': False}},\n",
       "   'parser': {'labels': {'@readers': 'spacy.read_labels.v1',\n",
       "     'path': 'corpus/labels/parser.json',\n",
       "     'require': False}},\n",
       "   'tagger': {'labels': {'@readers': 'spacy.read_labels.v1',\n",
       "     'path': 'corpus/labels/tagger.json',\n",
       "     'require': False}}},\n",
       "  'lookups': {'@misc': 'spacy.LookupsDataLoader.v1',\n",
       "   'lang': '${nlp.lang}',\n",
       "   'tables': ['lexeme_norm']},\n",
       "  'tokenizer': {}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a2c29",
   "metadata": {},
   "source": [
    "This can be a little difficult to read, though, when rendered as JSON. It is a bit easier, if we use the `.to_str()` method to convert the JSON into a readable string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9224ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "train = null\n",
      "dev = null\n",
      "vectors = null\n",
      "init_tok2vec = null\n",
      "\n",
      "[system]\n",
      "gpu_allocator = null\n",
      "seed = 0\n",
      "\n",
      "[nlp]\n",
      "lang = \"en\"\n",
      "pipeline = [\"tok2vec\",\"tagger\",\"parser\",\"senter\",\"attribute_ruler\",\"lemmatizer\",\"ner\"]\n",
      "disabled = [\"senter\"]\n",
      "before_creation = null\n",
      "after_creation = null\n",
      "after_pipeline_creation = null\n",
      "batch_size = 256\n",
      "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
      "vectors = {\"@vectors\":\"spacy.Vectors.v1\"}\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.attribute_ruler]\n",
      "factory = \"attribute_ruler\"\n",
      "scorer = {\"@scorers\":\"spacy.attribute_ruler_scorer.v1\"}\n",
      "validate = false\n",
      "\n",
      "[components.lemmatizer]\n",
      "factory = \"lemmatizer\"\n",
      "mode = \"rule\"\n",
      "model = null\n",
      "overwrite = false\n",
      "scorer = {\"@scorers\":\"spacy.lemmatizer_scorer.v1\"}\n",
      "\n",
      "[components.ner]\n",
      "factory = \"ner\"\n",
      "incorrect_spans_key = null\n",
      "moves = null\n",
      "scorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\n",
      "update_with_oracle_cut_size = 100\n",
      "\n",
      "[components.ner.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"ner\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = true\n",
      "nO = null\n",
      "\n",
      "[components.ner.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.ner.model.tok2vec.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = 96\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\n",
      "rows = [5000,1000,2500,2500]\n",
      "include_static_vectors = false\n",
      "\n",
      "[components.ner.model.tok2vec.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 96\n",
      "depth = 4\n",
      "window_size = 1\n",
      "maxout_pieces = 3\n",
      "\n",
      "[components.parser]\n",
      "factory = \"parser\"\n",
      "learn_tokens = false\n",
      "min_action_freq = 30\n",
      "moves = null\n",
      "scorer = {\"@scorers\":\"spacy.parser_scorer.v1\"}\n",
      "update_with_oracle_cut_size = 100\n",
      "\n",
      "[components.parser.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"parser\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = true\n",
      "nO = null\n",
      "\n",
      "[components.parser.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\n",
      "width = ${components.tok2vec.model.encode:width}\n",
      "upstream = \"tok2vec\"\n",
      "\n",
      "[components.senter]\n",
      "factory = \"senter\"\n",
      "overwrite = false\n",
      "scorer = {\"@scorers\":\"spacy.senter_scorer.v1\"}\n",
      "\n",
      "[components.senter.model]\n",
      "@architectures = \"spacy.Tagger.v2\"\n",
      "nO = null\n",
      "normalize = false\n",
      "\n",
      "[components.senter.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.senter.model.tok2vec.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = 16\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\",\"SPACY\"]\n",
      "rows = [1000,500,500,500,50]\n",
      "include_static_vectors = false\n",
      "\n",
      "[components.senter.model.tok2vec.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 16\n",
      "depth = 2\n",
      "window_size = 1\n",
      "maxout_pieces = 2\n",
      "\n",
      "[components.tagger]\n",
      "factory = \"tagger\"\n",
      "label_smoothing = 0.0\n",
      "neg_prefix = \"!\"\n",
      "overwrite = false\n",
      "scorer = {\"@scorers\":\"spacy.tagger_scorer.v1\"}\n",
      "\n",
      "[components.tagger.model]\n",
      "@architectures = \"spacy.Tagger.v2\"\n",
      "nO = null\n",
      "normalize = false\n",
      "\n",
      "[components.tagger.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\n",
      "width = ${components.tok2vec.model.encode:width}\n",
      "upstream = \"tok2vec\"\n",
      "\n",
      "[components.tok2vec]\n",
      "factory = \"tok2vec\"\n",
      "\n",
      "[components.tok2vec.model]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.tok2vec.model.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = ${components.tok2vec.model.encode:width}\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\",\"SPACY\",\"IS_SPACE\"]\n",
      "rows = [5000,1000,2500,2500,50,50]\n",
      "include_static_vectors = false\n",
      "\n",
      "[components.tok2vec.model.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 96\n",
      "depth = 4\n",
      "window_size = 1\n",
      "maxout_pieces = 3\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "gold_preproc = false\n",
      "max_length = 0\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "gold_preproc = false\n",
      "max_length = 0\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[training]\n",
      "train_corpus = \"corpora.train\"\n",
      "dev_corpus = \"corpora.dev\"\n",
      "seed = ${system:seed}\n",
      "gpu_allocator = ${system:gpu_allocator}\n",
      "dropout = 0.1\n",
      "accumulate_gradient = 1\n",
      "patience = 5000\n",
      "max_epochs = 0\n",
      "max_steps = 100000\n",
      "eval_frequency = 1000\n",
      "frozen_components = []\n",
      "before_to_disk = null\n",
      "annotating_components = []\n",
      "before_update = null\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_words.v1\"\n",
      "discard_oversize = false\n",
      "tolerance = 0.2\n",
      "get_length = null\n",
      "\n",
      "[training.batcher.size]\n",
      "@schedules = \"compounding.v1\"\n",
      "start = 100\n",
      "stop = 1000\n",
      "compound = 1.001\n",
      "t = 0.0\n",
      "\n",
      "[training.logger]\n",
      "@loggers = \"spacy.ConsoleLogger.v1\"\n",
      "progress_bar = false\n",
      "\n",
      "[training.optimizer]\n",
      "@optimizers = \"Adam.v1\"\n",
      "beta1 = 0.9\n",
      "beta2 = 0.999\n",
      "L2_is_weight_decay = true\n",
      "L2 = 0.01\n",
      "grad_clip = 1.0\n",
      "use_averages = true\n",
      "eps = 0.00000001\n",
      "learn_rate = 0.001\n",
      "\n",
      "[training.score_weights]\n",
      "tag_acc = 0.16\n",
      "dep_uas = 0.0\n",
      "dep_las = 0.16\n",
      "dep_las_per_type = null\n",
      "sents_p = null\n",
      "sents_r = null\n",
      "sents_f = 0.02\n",
      "lemma_acc = 0.5\n",
      "ents_f = 0.16\n",
      "ents_p = 0.0\n",
      "ents_r = 0.0\n",
      "ents_per_type = null\n",
      "speed = 0.0\n",
      "\n",
      "[pretraining]\n",
      "\n",
      "[initialize]\n",
      "vocab_data = null\n",
      "vectors = ${paths.vectors}\n",
      "init_tok2vec = ${paths.init_tok2vec}\n",
      "before_init = null\n",
      "after_init = null\n",
      "\n",
      "[initialize.components]\n",
      "\n",
      "[initialize.components.ner]\n",
      "\n",
      "[initialize.components.ner.labels]\n",
      "@readers = \"spacy.read_labels.v1\"\n",
      "path = \"corpus/labels/ner.json\"\n",
      "require = false\n",
      "\n",
      "[initialize.components.parser]\n",
      "\n",
      "[initialize.components.parser.labels]\n",
      "@readers = \"spacy.read_labels.v1\"\n",
      "path = \"corpus/labels/parser.json\"\n",
      "require = false\n",
      "\n",
      "[initialize.components.tagger]\n",
      "\n",
      "[initialize.components.tagger.labels]\n",
      "@readers = \"spacy.read_labels.v1\"\n",
      "path = \"corpus/labels/tagger.json\"\n",
      "require = false\n",
      "\n",
      "[initialize.lookups]\n",
      "@misc = \"spacy.LookupsDataLoader.v1\"\n",
      "lang = ${nlp.lang}\n",
      "tables = [\"lexeme_norm\"]\n",
      "\n",
      "[initialize.tokenizer]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.config.to_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fd2d8",
   "metadata": {},
   "source": [
    "It's a bit beyond the scope of this notebook to dive into the entirety of this config file, but it is worth noting that this is the basis for defining and structuring a pipeline manually. The reason I am providing this example here is because we will be creating our own spaCy config files in order to properly define and create a spaCy pipeline for working with LLMs.\n",
    "\n",
    "# Introduction to `spacy-llm`\n",
    "\n",
    "The best way to work with LLMs inside of spaCy is to use the spaCy-created package `spacy-llm`. We've already installed it up above. In order to begin working with spacy-llm, you need to assemble a pipeline. There are several ways to do this. For this tutorial, we will be using a config file. The reason for this is because it allows you to have more easily-reproducible results. Rather than pasting a code snippet into other notebooks, you can reuse the same config file.\n",
    "\n",
    "For this course, all config files will be located in `./assets`. Remember, because our notebooks are in `./notebooks`, we need to navigate out of notebooks and into assets, to do that, we can use the following directory `../assets`. The `..` brings us back to the root directory of this project.\n",
    "\n",
    "To begin working with spacy-llm, let's go ahead and import `assemble` from `spacy_llm.util`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbef10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_llm.util import assemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b3404",
   "metadata": {},
   "source": [
    "Now that we have everything imported, we can go ahead and create our pipeline. Before we do, though, we need to make sure our environment variable for OPENAI_API_KEY is set correctly. We have already done this at the top of the notebook. Remember, when working with notebooks, you MUST always set your environment variables first with the `os` module or set that as environment variables.\n",
    "\n",
    "The code you should use is this:\n",
    "\n",
    "```python\n",
    "import os\n",
    "# uncomment this out if you are using a Mac. This is a bug and with spacy-llm and pytorch on a Mac and this resolves it for now.\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\n",
    "```\n",
    "\n",
    "SpaCy requires that your api keys be set as environment variables, rather than used in-script. The more secure way to do this is to use `export` in the terminal. Because we are working on different operating systems and different computers, we are using `os` to ensure that all students have a shared experience.\n",
    "\n",
    "Once your api key is set correctly, we can now begin working with assembling our pipeline. To do that, we will use `assemble()` and pass a single argument: the path to our config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f649ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = assemble(\"../assets/openai-ner.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ae164",
   "metadata": {},
   "source": [
    "But what does this config file look like? It looks like this:\n",
    "\n",
    "```yaml\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"llm_ner\"]\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.llm_ner]\n",
    "factory = \"llm\"\n",
    "\n",
    "[components.llm_ner.task]\n",
    "@llm_tasks = \"spacy.NER.v2\"\n",
    "labels = [\"GPE\", \"PERSON\"]\n",
    "\n",
    "[components.llm_ner.model]\n",
    "@llm_models = \"spacy.GPT-3-5.v3\"\n",
    "config = {\"temperature\": 0.0}\n",
    "\n",
    "```\n",
    "\n",
    "What's happening here exactly? Well, we are defining our LLM pipeline within spaCy. Let's break down each line.\n",
    "\n",
    "# Breakdown of spaCy LLM Configuration\n",
    "\n",
    "Let's go through each section of the configuration file and explain what each line means:\n",
    "\n",
    "```yaml\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"llm_ner\"]\n",
    "```\n",
    "\n",
    "- `[nlp]`: This section defines general settings for the NLP (Natural Language Processing) model.\n",
    "- `lang = \"en\"`: This specifies that the language of the model is English.\n",
    "- `pipeline = [\"llm_ner\"]`: This defines the components of the processing pipeline. Here, we have only one component named \"llm_ner\".\n",
    "\n",
    "```yaml\n",
    "[components]\n",
    "```\n",
    "\n",
    "- `[components]`: This section introduces the configuration for individual components in the pipeline.\n",
    "\n",
    "```yaml\n",
    "[components.llm_ner]\n",
    "factory = \"llm\"\n",
    "```\n",
    "\n",
    "- `[components.llm_ner]`: This subsection configures the \"llm_ner\" component we specified in the pipeline.\n",
    "- `factory = \"llm\"`: This tells spaCy to use the LLM (Large Language Model) factory to create this component.\n",
    "\n",
    "```yaml\n",
    "[components.llm_ner.task]\n",
    "@llm_tasks = \"spacy.NER.v2\"\n",
    "labels = [\"GPE\", \"PERSON\"]\n",
    "```\n",
    "\n",
    "- `[components.llm_ner.task]`: This subsection defines the specific task for the LLM component.\n",
    "- `@llm_tasks = \"spacy.NER.v2\"`: This specifies that we're using version 2 of spaCy's Named Entity Recognition (NER) task.\n",
    "- `labels = [\"COMPOSER\"]`: This defines the label(s) that the NER task should identify. In this case, it's looking for entities labeled as \"GPE\" or \"PERSON\". GPE stands for Geo-Political Entity.\n",
    "\n",
    "```yaml\n",
    "[components.llm_ner.model]\n",
    "@llm_models = \"spacy.GPT-3-5.v3\"\n",
    "config = {\"temperature\": 0.0}\n",
    "```\n",
    "\n",
    "- `[components.llm_ner.model]`: This subsection configures the specific LLM model to use.\n",
    "- `@llm_models = \"spacy.GPT-3-5.v3\"`: This specifies that we're using version 3 of the GPT-3.5 model integration in spaCy.\n",
    "- `config = {\"temperature\": 0.0}`: This sets the configuration for the GPT-3.5 model. The \"temperature\" parameter controls the randomness of the model's output. A value of 0.0 means the model will always choose the most likely next word, making the output more deterministic and focused.\n",
    "\n",
    "In summary, this configuration sets up a spaCy pipeline that uses GPT-3.5 to perform Named Entity Recognition, specifically looking for entities that can be labeled as \"GPE\" or \"PERSON\". The pipeline is set to process English text and aims to produce consistent, focused results due to the low temperature setting of the model.\n",
    "\n",
    "## Models\n",
    "\n",
    "When it comes to models, spaCy has a lot of flexibility with most of the major APIs. Here is a table that comes from spaCy's documentation. To stay up-to-date, make sure you visit their page directly [here](https://spacy.io/api/large-language-models#models).\n",
    "\n",
    "\n",
    "| MODEL                     | PROVIDER            | SUPPORTED NAMES                                                                 | DEFAULT NAME         | DEFAULT CONFIG                           |\n",
    "|---------------------------|---------------------|--------------------------------------------------------------------------------|----------------------|------------------------------------------|\n",
    "| spacy.GPT-4.v1            | OpenAI              | [\"gpt-4\", \"gpt-4-0314\", \"gpt-4-32k\", \"gpt-4-32k-0314\"]                          | \"gpt-4\"              | {}                                       |\n",
    "| spacy.GPT-4.v2            | OpenAI              | [\"gpt-4\", \"gpt-4-0314\", \"gpt-4-32k\", \"gpt-4-32k-0314\"]                          | \"gpt-4\"              | {temperature=0.0}                        |\n",
    "| spacy.GPT-4.v3            | OpenAI              | All names of GPT-4 models offered by OpenAI                                     | \"gpt-4\"              | {temperature=0.0}                        |\n",
    "| spacy.GPT-3-5.v1          | OpenAI              | [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-0613-16k\", \"gpt-3.5-turbo-instruct\"] | \"gpt-3.5-turbo\"      | {}                                       |\n",
    "| spacy.GPT-3-5.v2          | OpenAI              | [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-0613-16k\", \"gpt-3.5-turbo-instruct\"] | \"gpt-3.5-turbo\"      | {temperature=0.0}                        |\n",
    "| spacy.GPT-3-5.v3          | OpenAI              | All names of GPT-3.5 models offered by OpenAI                                   | \"gpt-3.5-turbo\"      | {temperature=0.0}                        |\n",
    "| spacy.Davinci.v1          | OpenAI              | [\"davinci\"]                                                                     | \"davinci\"            | {}                                       |\n",
    "| spacy.Davinci.v2          | OpenAI              | [\"davinci\"]                                                                     | \"davinci\"            | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Text-Davinci.v1     | OpenAI              | [\"text-davinci-003\", \"text-davinci-002\"]                                        | \"text-davinci-003\"   | {}                                       |\n",
    "| spacy.Text-Davinci.v2     | OpenAI              | [\"text-davinci-003\", \"text-davinci-002\"]                                        | \"text-davinci-003\"   | {temperature=0.0, max_tokens=1000}       |\n",
    "| spacy.Code-Davinci.v1     | OpenAI              | [\"code-davinci-002\"]                                                            | \"code-davinci-002\"   | {}                                       |\n",
    "| spacy.Code-Davinci.v2     | OpenAI              | [\"code-davinci-002\"]                                                            | \"code-davinci-002\"   | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Curie.v1            | OpenAI              | [\"curie\"]                                                                       | \"curie\"              | {}                                       |\n",
    "| spacy.Curie.v2            | OpenAI              | [\"curie\"]                                                                       | \"curie\"              | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Text-Curie.v1       | OpenAI              | [\"text-curie-001\"]                                                              | \"text-curie-001\"     | {}                                       |\n",
    "| spacy.Text-Curie.v2       | OpenAI              | [\"text-curie-001\"]                                                              | \"text-curie-001\"     | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Babbage.v1          | OpenAI              | [\"babbage\"]                                                                     | \"babbage\"            | {}                                       |\n",
    "| spacy.Babbage.v2          | OpenAI              | [\"babbage\"]                                                                     | \"babbage\"            | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Text-Babbage.v1     | OpenAI              | [\"text-babbage-001\"]                                                            | \"text-babbage-001\"   | {}                                       |\n",
    "| spacy.Text-Babbage.v2     | OpenAI              | [\"text-babbage-001\"]                                                            | \"text-babbage-001\"   | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Ada.v1              | OpenAI              | [\"ada\"]                                                                         | \"ada\"                | {}                                       |\n",
    "| spacy.Ada.v2              | OpenAI              | [\"ada\"]                                                                         | \"ada\"                | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Text-Ada.v1         | OpenAI              | [\"text-ada-001\"]                                                                | \"text-ada-001\"       | {}                                       |\n",
    "| spacy.Text-Ada.v2         | OpenAI              | [\"text-ada-001\"]                                                                | \"text-ada-001\"       | {temperature=0.0, max_tokens=500}        |\n",
    "| spacy.Azure.v1            | Microsoft, OpenAI   | Arbitrary values                                                                | No default           | {temperature=0.0}                        |\n",
    "| spacy.Command.v1          | Cohere              | [\"command\", \"command-light\", \"command-light-nightly\", \"command-nightly\"]         | \"command\"            | {}                                       |\n",
    "| spacy.Claude-2-1.v1       | Anthropic           | [\"claude-2-1\"]                                                                  | \"claude-2-1\"         | {}                                       |\n",
    "| spacy.Claude-2.v1         | Anthropic           | [\"claude-2\", \"claude-2-100k\"]                                                   | \"claude-2\"           | {}                                       |\n",
    "| spacy.Claude-1.v1         | Anthropic           | [\"claude-1\", \"claude-1-100k\"]                                                   | \"claude-1\"           | {}                                       |\n",
    "| spacy.Claude-1-0.v1       | Anthropic           | [\"claude-1.0\"]                                                                  | \"claude-1.0\"         | {}                                       |\n",
    "| spacy.Claude-1-2.v1       | Anthropic           | [\"claude-1.2\"]                                                                  | \"claude-1.2\"         | {}                                       |\n",
    "| spacy.Claude-1-3.v1       | Anthropic           | [\"claude-1.3\", \"claude-1.3-100k\"]                                               | \"claude-1.3\"         | {}                                       |\n",
    "| spacy.Claude-instant-1.v1 | Anthropic           | [\"claude-instant-1\", \"claude-instant-1-100k\"]                                   | \"claude-instant-1\"   | {}                                       |\n",
    "| spacy.Claude-instant-1-1.v1| Anthropic          | [\"claude-instant-1.1\", \"claude-instant-1.1-100k\"]                               | \"claude-instant-1.1\" | {}                                       |\n",
    "| spacy.PaLM.v1             | Google              | [\"chat-bison-001\", \"text-bison-001\"]                                            | \"text-bison-001\"     | {temperature=0.0}                        |\n",
    "\n",
    "\n",
    "## Creating our First Doc\n",
    "\n",
    "Now that we have created our pipeline, let's create a text and run it through the pipeline. Our syntax from here on out remains precisely the same as any other spaCy pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1daf61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Sir\n",
    "I understand Mr Skinner is gone to Philadelphia. You will keep the inclosed Letter for him till he returns, when You will take the earliest opportunity of delivering it to him. I desire to see him as soon as he arrives & have written to him for the purpose.1\n",
    "\n",
    "You will inform the Officer who came with a flag to Elizabeth Town Yesterday—that he is not to wait for an Answer to the Letters he brought; and that One will be transmitted by an early conveyance.2 You will deliver him the Letters in the packet which accompanies this.3 I am Sir Yr Hbl. sert\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f72844",
   "metadata": {},
   "source": [
    "This is the same text we used in our previous notebook, but notice that this particular text has the archaic style English of the 18th century preserved. Let's see how good our GPT-3.5 annotations are with `displacy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5400dbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Sir<br>I understand \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mr Skinner\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is gone to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philadelphia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". You will keep the inclosed Letter for him till he returns, when You will take the earliest opportunity of delivering it to him. I desire to see him as soon as he arrives &amp; have written to him for the purpose.1<br><br>You will inform the Officer who came with a flag to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elizabeth Town\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Yesterday—that he is not to wait for an Answer to the Letters he brought; and that One will be transmitted by an early conveyance.2 You will deliver him the Letters in the packet which accompanies this.3 I am Sir Yr Hbl. sert<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cda3be",
   "metadata": {},
   "source": [
    "The results here are perfect. It has correctly labeled each label. Remember, you may have a slightly different output. That's okay (especially as you are working with more complex tasks.)\n",
    "\n",
    "Let's see how well this process works with a more challenging text. The following text comes from the [FIND PROJECT NAME]. Our goal is to identify the composers in the text. Let's see how well our pipeline works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e89e1997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Program Hodle Chrlstus Notus Est Jan Peterszoon Sweellnck Sung in Latin 1562 -1621 Today Christ is born Today the Saviour hos appeared On earth the angels sing the archangels rejoice and the righteous ore glad saying `` Glory to God in the highest Noell Alleluia/ '' Rorate Coen Giovanni Perlulgl do Palestrina Sung in Latin 1525 -1594 Pour out dew from above you heavens and let the clouds rain down the Just One Let the earth open and bring forth a saviour Show us your mercy 0 Lord and grant us your salvation Come 0 Lord and do not delay Alleluia ! Allelulal Ascendlt Deus WIiiiam Byrd Sung in Latin 1543 -1623 Alleluia ! God hos ascended in jubilation and Christ the Lord with the sound of the trumpets Alleluia/ II Nunc Dfmlttls Christian Figueroa tenor The Te Deum of Sandor Slk Ill Sergei Rachmaninoff 1873-1943 Zoltan Kodaly 1882 -1967 Motet `` Lobet den Herrn alle Heiden '' \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    J. S. Bach\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in German 1685 -1750 Praise the Lord all ye notions praise him all ye people For his mercy and truth watch over us for evermore Alleluia/ -intermission -<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "composer_text = \"\"\"\n",
    "Program Hodle Chrlstus Notus Est Jan Peterszoon Sweellnck Sung in Latin 1562 -1621 Today Christ is born Today the Saviour hos appeared On earth the angels sing the archangels rejoice and the righteous ore glad saying `` Glory to God in the highest Noell Alleluia/ '' Rorate Coen Giovanni Perlulgl do Palestrina Sung in Latin 1525 -1594 Pour out dew from above you heavens and let the clouds rain down the Just One Let the earth open and bring forth a saviour Show us your mercy 0 Lord and grant us your salvation Come 0 Lord and do not delay Alleluia ! Allelulal Ascendlt Deus WIiiiam Byrd Sung in Latin 1543 -1623 Alleluia ! God hos ascended in jubilation and Christ the Lord with the sound of the trumpets Alleluia/ II Nunc Dfmlttls Christian Figueroa tenor The Te Deum of Sandor Slk Ill Sergei Rachmaninoff 1873-1943 Zoltan Kodaly 1882 -1967 Motet `` Lobet den Herrn alle Heiden '' J. S. Bach Sung in German 1685 -1750 Praise the Lord all ye notions praise him all ye people For his mercy and truth watch over us for evermore Alleluia/ -intermission -\n",
    "\"\"\"\n",
    "colors = {\n",
    "    \"COMPOSER\": \"#a8d5e2\",      # Light blue\n",
    "    \"COMPOSITION\": \"#c2e8c4\",   # Light green\n",
    "    \"DATE_RANGE\": \"#f9c2c2\",    # Light red\n",
    "    \"LANGUAGE\": \"#f7e1a1\"       # Light yellow\n",
    "}\n",
    "\n",
    "options={\"colors\":colors}\n",
    "\n",
    "nlp_composer = assemble(\"../assets/openai-ner-composer.cfg\")\n",
    "doc_composer = nlp_composer(composer_text)\n",
    "displacy.render(doc_composer, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d19a920",
   "metadata": {},
   "source": [
    "This looks very bad. Let's break down one of the key issues. While we correctly identified `J.S. Bach`, we missed all other true positives. Why is that? For one, we are working with an NER label that is not traditional. I don't know of any datasets that label composers in this way. Secondly, we are using GPT-3.5. For more complex tasks, we should be using GPT-4. I have prepared for us another config that uses GPT-4. Let's load up that config and rerun this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11642501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Program Hodle Chrlstus Notus Est \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jan Peterszoon Sweellnck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in Latin 1562 -1621 Today Christ is born Today the Saviour hos appeared On earth the angels sing the archangels rejoice and the righteous ore glad saying `` Glory to God in the highest Noell Alleluia/ '' Rorate Coen \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Giovanni Perlulgl do Palestrina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in Latin 1525 -1594 Pour out dew from above you heavens and let the clouds rain down the Just One Let the earth open and bring forth a saviour Show us your mercy 0 Lord and grant us your salvation Come 0 Lord and do not delay Alleluia ! Allelulal Ascendlt Deus \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WIiiiam Byrd\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in Latin 1543 -1623 Alleluia ! God hos ascended in jubilation and Christ the Lord with the sound of the trumpets Alleluia/ II Nunc Dfmlttls \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Christian Figueroa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " tenor The Te Deum of \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sandor Slk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Ill \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sergei Rachmaninoff\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " 1873-1943 \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zoltan Kodaly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " 1882 -1967 Motet `` Lobet den Herrn alle Heiden '' \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    J. S. Bach\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in German 1685 -1750 Praise the Lord all ye notions praise him all ye people For his mercy and truth watch over us for evermore Alleluia/ -intermission -<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_composer = assemble(\"../assets/openai-ner-composer-good.cfg\")\n",
    "doc_composer = nlp_composer(composer_text)\n",
    "displacy.render(doc_composer, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f933d",
   "metadata": {},
   "source": [
    "This is looking a lot better! Why do we have such improvement? For one, GPT-4 is a much larger model. It was trained on more material and has a better understanding of more complex things. Why don't we just use GPT-4 for everything then? Well, GPT-4 is drastically more expensive than GPT-3.5. You really want to use GPT-4 when the task is complex and cannot be done with 3.5.\n",
    "\n",
    "But GPT-4 can do a lot more than label composer. We can also label a lot of other things in the text, like COMPOSITION, DATE_RANGE, and LANGUAGE. Let's load up another config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f598aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Program \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hodle Chrlstus Notus Est\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jan Peterszoon Sweellnck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in \n",
       "<mark class=\"entity\" style=\"background: #f7e1a1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1562 -1621\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " Today Christ is born Today the Saviour hos appeared On earth the angels sing the archangels rejoice and the righteous ore glad saying `` Glory to God in the highest Noell Alleluia/ '' \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rorate Coen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Giovanni Perlulgl do Palestrina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in \n",
       "<mark class=\"entity\" style=\"background: #f7e1a1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1525 -1594\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " Pour out dew from above you heavens and let the clouds rain down the Just One Let the earth open and bring forth a saviour Show us your mercy 0 Lord and grant us your salvation Come 0 Lord and do not delay Alleluia ! Allelulal \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ascendlt Deus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WIiiiam Byrd\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in \n",
       "<mark class=\"entity\" style=\"background: #f7e1a1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1543 -1623\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " Alleluia ! God hos ascended in jubilation and Christ the Lord with the sound of the trumpets Alleluia/ II \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nunc Dfmlttls\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Christian Figueroa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " tenor \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Te Deum of Sandor Slk Ill\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sergei Rachmaninoff\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1873-1943\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zoltan Kodaly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1882 -1967\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c2e8c4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Motet `` Lobet den Herrn alle Heiden ''\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSITION</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #a8d5e2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    J. S. Bach\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPOSER</span>\n",
       "</mark>\n",
       " Sung in \n",
       "<mark class=\"entity\" style=\"background: #f7e1a1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    German\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #f9c2c2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1685 -1750\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE_RANGE</span>\n",
       "</mark>\n",
       " Praise the Lord all ye notions praise him all ye people For his mercy and truth watch over us for evermore Alleluia/ -intermission -<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_composer = assemble(\"../assets/openai-ner-composer-good-all.cfg\")\n",
    "doc_composer = nlp_composer(composer_text)\n",
    "displacy.render(doc_composer, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f52031",
   "metadata": {},
   "source": [
    "Here we can see how well our extra labels perform alongside composers. Are the results perfect? No. But that's okay. No machine learning model is perfect. The big question at this stage is how well does this approach work on domain-specific data?\n",
    "\n",
    "# In-Class Exercise\n",
    "\n",
    "Let's test this. For this portion of the class, you will:\n",
    "\n",
    "1) Build your own config file, using the ones provided as a template. You should really only change the labels and models section of the config.\n",
    "2) Paste in your text in the code cell below.\n",
    "3) Create your pipeline\n",
    "4) Process the text\n",
    "5) Visualize the text\n",
    "\n",
    "Where does your approach work? Where does it fail? How does it compare to the other spaCy models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa06e3",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6aaff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function spacy_llm.tasks.textcat.util.reduce_shards_to_doc.<locals>.<lambda>()>,\n",
       "            {'NON_TOXIC': 0.0, 'TOXIC': 1.0})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"\"\"\n",
    "Tweet:\n",
    "You are terrible!\n",
    "\"\"\"\n",
    "\n",
    "nlp_textcat = assemble(\"../assets/openai-textcat.cfg\")\n",
    "doc_textcat = nlp_textcat(tweet)\n",
    "doc_textcat.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a6095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
